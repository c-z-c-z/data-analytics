{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains original code that I wrote for the purpose of this project\n",
    "#It was written to obtain specific formats/inputs I needed for other functions\n",
    "#or to create functions that I needed to perform the analyses I was interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearranging .value_counts() output based on specific label order\n",
    "\n",
    "def ordered_counts(df, col, order):\n",
    "    counts = []\n",
    "    for item in order:\n",
    "        counts.append(df[col].value_counts()[item])\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical functions\n",
    "\n",
    "#Z-tests of proportion -- one and two sample\n",
    "\n",
    "def one_sample_z(p0, p, n, critval):\n",
    "    numerator = p-p0\n",
    "    variance = p0*(1-p0)\n",
    "    denom = math.sqrt(variance/n)\n",
    "    z = round((numerator/denom), 2)\n",
    "    if z>critval or z<(-1*critval):\n",
    "        result = 'reject null hypothesis'\n",
    "    else:\n",
    "        result = 'fail to reject null hypothesis'\n",
    "    return z, result\n",
    "\n",
    "def two_sample_z_with_p(p1, p2, n1, n2, critval):\n",
    "    p = (p1 + p2)/2\n",
    "    numerator = p1 - p2\n",
    "    variance = p*(1-p)\n",
    "    sizes = (1/n1 + 1/n2)\n",
    "    denom = math.sqrt(variance * sizes)\n",
    "    z = round((numerator/denom), 2)\n",
    "    if z>critval or z<(-1*critval):\n",
    "        result = 'reject null hypothesis'\n",
    "    else:\n",
    "        result = 'fail to reject null hypothesis'\n",
    "    return z, result\n",
    "\n",
    "\n",
    "#For chi-square tests -- frequencies\n",
    "#After frequencies were calculated, chi-square function from scipy.stats was used\n",
    "\n",
    "def get_exp_freq(cat1lvls, cat2lvls, cat1counts, cat2counts):\n",
    "    exp_dict = {}\n",
    "    for i in range(len(cat1lvls)):\n",
    "        exp_dict[cat1lvls[i]] = []\n",
    "        for j in range(len(cat2lvls)):\n",
    "            prob=round((cat1counts[i]*cat2counts[j])/3000, 3)\n",
    "            exp_dict[cat1lvls[i]].append(prob)\n",
    "    return exp_dict\n",
    "\n",
    "def get_obs_freq(cat1lvls, cat2lvls, grouped_data):\n",
    "    obs_dict = {}\n",
    "    for i in range(len(cat1lvls)):\n",
    "        c = cat1lvls[i]\n",
    "        obs_dict[c] = []\n",
    "        for j in range(len(cat2lvls)):\n",
    "            c2 = cat2lvls[j]\n",
    "            if c2 not in grouped_data[c]:\n",
    "                obs_dict[c].append(0)\n",
    "            else:\n",
    "                obs_dict[c].append(grouped_data[c][c2])\n",
    "    return obs_dict\n",
    "#I'm aware that this could also have been done without having to aggregate data using\n",
    "#groupby prior to executing this function -- also could have been written by passing\n",
    "#original data frame and relevant columns and executing groupby within the function\n",
    "#similarly to how I wrote the get_heatmap function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilities of each level of an individual variable\n",
    "#rounded to 3 decimal places\n",
    "\n",
    "def get_probs(data, levels):\n",
    "    prob_dict = {}\n",
    "    for level in levels:\n",
    "        prob_dict[level] = (round(data[level][0]/(data[level][0]+data[level][1]),3), \n",
    "                           round(data[level][1]/(data[level][0]+data[level][1]),3))\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries of frequencies for heatmaps\n",
    "\n",
    "def freq_dict(grouped_data, key_labels, value_labels):\n",
    "    freqs = {}\n",
    "    for lab in key_labels:\n",
    "        freqs[lab] = {}\n",
    "        for lab2 in value_labels:\n",
    "            if lab == lab2:\n",
    "                freqs[lab][lab2] = 0\n",
    "            elif lab2 not in grouped_data[lab]:\n",
    "                freqs[lab][lab2] = 0\n",
    "            else:\n",
    "                freqs[lab][lab2] = grouped_data[lab][lab2]\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmaps in Appendix C were generated using this function\n",
    "\n",
    "def get_heatmap(data, x_axis, y_axis, x_labels, y_labels, save_fig=False, file_name=None):\n",
    "    grouped = data.groupby([y_axis])[x_axis].value_counts()\n",
    "    frequencies = freq_dict(grouped, y_labels, x_labels) #dictionary of frequencies\n",
    "    frequencies_df = pd.DataFrame.from_dict(frequencies, orient='index') #df from dict\n",
    "    frequencies_df = frequencies_df.reindex(axis=0, labels=y_labels) #ordering rows from labels\n",
    "    frequencies_df = frequencies_df.reindex(axis=1, labels=x_labels) #ordering columns from labels\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    ax = sns.heatmap(frequencies_df, annot=False, vmin=0, vmax=(round(grouped.max(), -1))+30, cmap='rocket_r')\n",
    "    ax.set_xlabel(x_axis, labelpad=20)\n",
    "    ax.set_ylabel(y_axis,labelpad=20)\n",
    "    if save_fig:\n",
    "        plt.savefig(file_name, bbox_inches='tight', format='eps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
